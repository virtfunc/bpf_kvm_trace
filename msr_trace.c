#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <time.h>
#include <bpf/libbpf.h>
#include <bpf/bpf.h>
#include <linux/types.h>
#include "msr_trace.h"
#include "msr_trace.skel.h" // Generated by bpftool

static unsigned long long start_ts;

// Simple tracking for "seen" MSRs to handle the '*' prefix
#define MAX_SEEN_MSRS 4096
static unsigned int seen_msrs[MAX_SEEN_MSRS];
static int seen_count = 0;

// Buffer for batching events to print every 200ms
#define MAX_BUFFERED_EVENTS 100000
static struct event buffered_events[MAX_BUFFERED_EVENTS];
static int buffered_count = 0;
static unsigned long long userspace_drops = 0;

static int is_seen(unsigned int msr) {
    for (int i = 0; i < seen_count; i++) {
        if (seen_msrs[i] == msr) return 1;
    }
    return 0;
}

static void mark_seen(unsigned int msr) {
    if (seen_count < MAX_SEEN_MSRS) {
        seen_msrs[seen_count++] = msr;
    }
}

static int handle_event(void *ctx, void *data, size_t data_sz)
{
    const struct event *e = data;
    if (buffered_count < MAX_BUFFERED_EVENTS) {
        buffered_events[buffered_count++] = *e;
    } else {
        userspace_drops++;
    }
    return 0;
}

static void flush_events(void)
{
    for (int i = 0; i < buffered_count; i++) {
        struct event *e = &buffered_events[i];
        char prefix = '*';

        if (is_seen(e->msr)) {
            prefix = ' ';
        } else {
            mark_seen(e->msr);
        }

        // Calculate elapsed time in ms relative to start
        unsigned int elapsed_ms = (e->ts - start_ts) / 1000000;

        const char *mode = e->is_write ? "WRITE" : "READ";

        if (e->result == 0) {
            // OK
            printf("%c[Time: %8u ms]  MSR: 0x%08x  Value: 0x%016llx  Mode: %-5s  Result: OK\n",
                   prefix, elapsed_ms, e->msr, e->value, mode);
        } else {
            // FAULT
            printf("%c[Time: %8u ms]  MSR: 0x%08x  Value: 0x%016llx  Mode: %-5s  Result: FAULT (Exception %2d)\n",
                   prefix, elapsed_ms, e->msr, e->value, mode, e->exception);
        }
    }
    buffered_count = 0;
}

static unsigned long long get_ktime_ns(void)
{
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return (unsigned long long)ts.tv_sec * 1000000000ull + ts.tv_nsec;
}

int main(int argc, char **argv)
{
    struct msr_trace_bpf *skel;
    struct ring_buffer *rb = NULL;
    int err;

    // Set up libbpf logging
    libbpf_set_print(NULL);

    // Open and load BPF application
    skel = msr_trace_bpf__open();
    if (!skel) {
        fprintf(stderr, "Failed to open and load BPF skeleton\n");
        return 1;
    }

    // Load & Verify
    err = msr_trace_bpf__load(skel);
    if (err) {
        fprintf(stderr, "Failed to load and verify BPF skeleton\n");
        goto cleanup;
    }

    // Attach tracepoints
    err = msr_trace_bpf__attach(skel);
    if (err) {
        fprintf(stderr, "Failed to attach BPF skeleton\n");
        goto cleanup;
    }

    // Set up ring buffer
    rb = ring_buffer__new(bpf_map__fd(skel->maps.rb), handle_event, NULL, NULL);
    if (!rb) {
        err = -1;
        fprintf(stderr, "Failed to create ring buffer\n");
        goto cleanup;
    }

    // Capture start time for relative timestamps
    // Note: This is an approximation. For exact alignment with kernel boot time
    // one might read /proc/uptime, but CLOCK_MONOTONIC is usually close enough
    // to bpf_ktime_get_ns() for relative diffs.
    start_ts = get_ktime_ns();

    printf("Tracing MSRs... Printing every 200ms.\n");

    int dropped_fd = bpf_map__fd(skel->maps.dropped);
    unsigned long long last_print_ts = get_ktime_ns();

    while (1) {
        // Poll for events (wait up to 10ms)
        err = ring_buffer__poll(rb, 10);
        if (err < 0) {
            fprintf(stderr, "Error polling ring buffer: %d\n", err);
            break;
        }
        
        // Consume all available events in the buffer
        err = ring_buffer__consume(rb);
        if (err < 0) {
            fprintf(stderr, "Error consuming ring buffer: %d\n", err);
            break;
        }

        unsigned long long now = get_ktime_ns();
        if ((now - last_print_ts) > 200000000ULL) {
            flush_events();
            last_print_ts = now;
        }

        if (userspace_drops > 0) {
            flush_events();
            fprintf(stderr, "\nError: Lost %llu events (userspace buffer full)\n", userspace_drops);
            err = -1;
            break;
        }

        __u32 key = 0;
        __u64 val = 0;
        if (bpf_map_lookup_elem(dropped_fd, &key, &val) == 0) {
            if (val > 0) {
                fprintf(stderr, "Error: Lost %llu events (ring buffer full)\n", (unsigned long long)val);
                err = -1;
                break;
            }
        }
    }

cleanup:
    ring_buffer__free(rb);
    msr_trace_bpf__destroy(skel);
    return -err;
}
